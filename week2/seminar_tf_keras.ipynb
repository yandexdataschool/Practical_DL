{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T21:05:26.096298Z",
     "start_time": "2017-09-03T21:05:26.092498Z"
    }
   },
   "source": [
    "# Your first CNN on CIFAR-10\n",
    "\n",
    "In this task you will: \n",
    "* define your first CNN architecture for CIFAR-10 dataset\n",
    "* train it from scratch\n",
    "* visualize learnt filters\n",
    "\n",
    "CIFAR-10 dataset contains 32x32 color images from 10 classes: __airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck__:\n",
    "<img src=\"cifar10.jpg\" style=\"width:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T23:44:03.372449Z",
     "start_time": "2017-09-03T23:43:54.182269Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T23:44:40.870302Z",
     "start_time": "2017-09-03T23:44:39.221603Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cifar import load_cifar10\n",
    "x_train,y_train,x_val,y_val,x_test,y_test = load_cifar10(\"cifar_data\")\n",
    "\n",
    "class_names = np.array(['airplane','automobile ','bird ','cat ','deer ','dog ','frog ','horse ','ship ','truck'])\n",
    "\n",
    "print (X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T00:27:41.648291Z",
     "start_time": "2017-09-04T00:27:41.644322Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Train samples:\", x_train.shape, y_train.shape)\n",
    "print(\"Test samples:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T23:44:41.009639Z",
     "start_time": "2017-09-03T23:44:40.877013Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
    "                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-03T23:44:42.285830Z",
     "start_time": "2017-09-03T23:44:41.011216Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show random images from train\n",
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_train))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.imshow(x_train[random_index, :])\n",
    "        ax.set_title(cifar10_classes[y_train[random_index, 0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to normalize inputs like this: $$x_{norm} = \\frac{x}{255} - 0.5$$\n",
    "\n",
    "We need to convert class labels to one-hot encoded vectors. Use __keras.utils.to_categorical__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T00:25:55.504781Z",
     "start_time": "2017-09-04T00:25:55.500823Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs\n",
    "# convert class labels to one-hot encoded, should have shape (?, NUM_CLASSES)\n",
    "y_train = ### YOUR CODE HERE\n",
    "y_test = ### YOUR CODE HERE\n",
    "\n",
    "x_val = ### YOUR CODE HERE\n",
    "x_val = ### YOUR CODE HERE\n",
    "\n",
    "y_test = ### YOUR CODE HERE\n",
    "y_test = ### YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T11:39:23.631230Z",
     "start_time": "2017-08-24T11:39:23.627975Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary building blocks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional networks are built from several types of layers:\n",
    "- [Conv2D](https://keras.io/layers/convolutional/#conv2d) - performs convolution:\n",
    "    - **filters**: number of output channels; \n",
    "    - **kernel_size**: an integer or tuple/list of 2 integers, specifying the width and height of the 2D convolution window;\n",
    "    - **padding**: padding=\"same\" adds zero padding to the input, so that the output has the same width and height, padding='valid' performs convolution only in locations where kernel and the input fully overlap;\n",
    "    - **activation**: \"relu\", \"tanh\", etc.\n",
    "    - **input_shape**: shape of input.\n",
    "- [MaxPooling2D](https://keras.io/layers/pooling/#maxpooling2d) - performs 2D max pooling.\n",
    "- [Flatten](https://keras.io/layers/core/#flatten) - flattens the input, does not affect the batch size.\n",
    "- [Dense](https://keras.io/layers/core/#dense) - fully-connected layer.\n",
    "- [Activation](https://keras.io/layers/core/#activation) - applies an activation function.\n",
    "- [LeakyReLU](https://keras.io/layers/advanced-activations/#leakyrelu) - applies leaky relu activation.\n",
    "- [Dropout](https://keras.io/layers/core/#dropout) - applies dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step\n",
    "\n",
    "Let's create a mini-convolutional network with roughly such architecture:\n",
    "* Input layer\n",
    "* 3x3 convolution with 10 filters and ReLU activation\n",
    "* 3x3 pooling (or set previous convolution stride to 3)\n",
    "* Dense layer with 100-neurons and ReLU activation\n",
    "* 10% dropout\n",
    "* Output dense layer.\n",
    "\n",
    "You need to define a model which takes __(None, 32, 32, 3)__ input and predicts __(None, 10)__ output with probabilities for all classes. __None__ in shapes stands for batch dimension.\n",
    "\n",
    "Simple feed-forward networks in Keras can be defined in the following way:\n",
    "\n",
    "```python\n",
    "model = Sequential()  # start feed-forward model definition\n",
    "model.add(Conv2D(..., input_shape=(32, 32, 3)))  # first layer needs to define \"input_shape\"\n",
    "\n",
    "...  # here comes a bunch of convolutional, pooling and dropout layers\n",
    "\n",
    "model.add(Dense(NUM_CLASSES))  # the last layer with neuron for each class\n",
    "model.add(Activation(\"softmax\"))  # output probabilities\n",
    "```\n",
    "\n",
    "\n",
    "Train it with Adam optimizer with default params.\n",
    "\n",
    "\n",
    "### Second step (after you've trained it)\n",
    "\n",
    "* Add batch_norm (with default params) between convolution and pooling\n",
    "\n",
    "Re-train the network with the same optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T11:39:23.739649Z",
     "start_time": "2017-08-24T11:39:23.632558Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T11:39:23.948546Z",
     "start_time": "2017-08-24T11:39:23.741012Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# describe model\n",
    "K.clear_session()  # clear default graph\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of your model can take approx. 4-8 minutes per epoch.\n",
    "\n",
    "During training you should observe the decrease in reported loss on training and validation.\n",
    "\n",
    "If the loss on training is not decreasing with epochs you should revise your model definition and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T12:18:39.059726Z",
     "start_time": "2017-08-24T11:39:23.949926Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INIT_LR = 5e-3  # initial learning rate\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "K.clear_session()  # clear default graph\n",
    "# don't call K.set_learning_phase() !!! (otherwise will enable dropout in train/test simultaneously)\n",
    "model = make_model()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # we train 10-way classification\n",
    "    optimizer=keras.optimizers.adamax(lr=INIT_LR),  # for SGD\n",
    "    metrics=['accuracy']  # report accuracy during training\n",
    ")\n",
    "\n",
    "\n",
    "# fit model\n",
    "model.fit(\n",
    "    x_train2, y_train2,  # prepared data\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(x_val, y_val),\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T12:18:39.103672Z",
     "start_time": "2017-08-24T12:18:39.061508Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save weights to file\n",
    "model.save_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T12:18:39.298255Z",
     "start_time": "2017-08-24T12:18:39.105314Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load weights from file (can call without model.fit)\n",
    "model.load_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T12:18:53.381943Z",
     "start_time": "2017-08-24T12:18:39.299830Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make test predictions\n",
    "y_pred_test = model.predict_proba(x_test)\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
    "y_pred_test_max_probas = np.max(y_pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T12:18:54.293970Z",
     "start_time": "2017-08-24T12:18:53.383809Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix and accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.title('Confusion matrix', fontsize=16)\n",
    "plt.imshow(confusion_matrix(y_test, y_pred_test_classes))\n",
    "plt.xticks(np.arange(10), cifar10_classes, rotation=45, fontsize=12)\n",
    "plt.yticks(np.arange(10), cifar10_classes, fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred_test_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T12:18:55.568152Z",
     "start_time": "2017-08-24T12:18:54.295958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inspect preditions\n",
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_test))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid('off')\n",
    "        ax.axis('off')\n",
    "        ax.imshow(x_test[random_index, :])\n",
    "        pred_label = cifar10_classes[y_pred_test_classes[random_index]]\n",
    "        pred_proba = y_pred_test_max_probas[random_index]\n",
    "        true_label = cifar10_classes[y_test[random_index, 0]]\n",
    "        ax.set_title(\"pred: {}\\nscore: {:.3}\\ntrue: {}\".format(\n",
    "               pred_label, pred_proba, true_label\n",
    "        ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main: Quest For A Better Network\n",
    "\n",
    "(please read it at least diagonally)\n",
    "\n",
    "* The ultimate quest is to create a network that has as high __accuracy__ as you can push it.\n",
    "* There is a __mini-report__ at the end that you will have to fill in. We recommend reading it first and filling it while you iterate.\n",
    " \n",
    "## Grading\n",
    "* starting at zero points\n",
    "* +2 for describing your iteration path in a report below.\n",
    "* +2 for building a network that gets above 20% accuracy\n",
    "* +1 for beating each of these milestones on __TEST__ dataset:\n",
    "    * 50% (5 total)\n",
    "    * 60% (6 total)\n",
    "    * 65% (7 total)\n",
    "    * 70% (8 total)\n",
    "    * 75% (9 total)\n",
    "    * 80% (10 total)\n",
    "    \n",
    "## Bonus points\n",
    "\n",
    "Common ways to get bonus points are:\n",
    "* Get higher score, obviously.\n",
    "* Anything special about your NN. For example \"A super-small/fast NN that gets 80%\" gets a bonus.\n",
    "* Any detailed analysis of the results. (saliency maps, whatever)\n",
    "\n",
    "## Restrictions\n",
    "* Please do NOT use pre-trained networks for this assignment until you reach 80%.\n",
    " * In other words, base milestones must be beaten without pre-trained nets (and such net must be present in the e-mail). After that, you can use whatever you want.\n",
    "* you __can__ use validation data for training, but you __can't'__ do anything with test data apart from running the evaluation procedure.\n",
    "\n",
    "## Tips on what can be done:\n",
    "\n",
    "\n",
    " * __Network size__\n",
    "   * MOAR neurons, \n",
    "   * MOAR layers, ([lasagne docs](http://lasagne.readthedocs.org))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "   * Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn!\n",
    "\n",
    " * __Convolution layers__\n",
    "   * they __are a must__ unless you have any super-ideas\n",
    "   * `network = lasagne.layers.Conv2DLayer(prev_layer,`\n",
    "    `                        num_filters = n_neurons,`\n",
    "    `                        filter_size = (filter width, filter height),`\n",
    "    `                        nonlinearity = some_nonlinearity)`\n",
    "   * Warning! Training convolutional networks can take long without GPU. That's okay.\n",
    "     * If you are CPU-only, we still recomment to try a simple convolutional architecture\n",
    "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
    "     * Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.\n",
    "     * __To reduce computation__ time by a factor in exchange for some accuracy drop, try using __stride__ parameter. A stride=2 convolution should take roughly 1/4 of the default (stride=1) one.\n",
    " \n",
    "   * Plenty other layers and architectures\n",
    "     * http://lasagne.readthedocs.org/en/latest/modules/layers.html\n",
    "     * batch normalization, pooling, etc\n",
    "\n",
    " * __Early Stopping__\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "     \n",
    "\n",
    " * __Faster optimization__ - \n",
    "   * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "   * __BatchNormalization__ (lasagne.layers.batch_norm) FTW!\n",
    "\n",
    "\n",
    " * __Regularize__ to prevent overfitting\n",
    "   * Add some L2 weight norm to the loss function, theano will do the rest\n",
    "     * Can be done manually or via - http://lasagne.readthedocs.org/en/latest/modules/regularization.html\n",
    "   * Dropout - to prevent overfitting\n",
    "     * `lasagne.layers.DropoutLayer(prev_layer, p=probability_to_zero_out)`   \n",
    "     * Don't overdo it. Check if it actually makes your network better\n",
    "   \n",
    "   \n",
    " * __Data augmemntation__ - getting 5x as large dataset for free is a great deal\n",
    "   * Zoom-in+slice = move\n",
    "   * Rotate+zoom(to remove black stripes)\n",
    "   * any other perturbations\n",
    "   * Add Noize (easiest: GaussianNoizeLayer)\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them.\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    " \n",
    " \n",
    "   \n",
    "There is a template for your solution below that you can opt to use or throw away and write it your way"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
