{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zdnjechqnucr5xy2t286c"
   },
   "source": [
    "### Generating human faces with Adversarial Networks (5 points)\n",
    "<img src=\"https://www.strangerdimensions.com/wp-content/uploads/2013/11/reception-robot.jpg\" width=320>\n",
    "This time we'll train a neural net to generate plausible human faces in all their subtlty: appearance, expression, accessories, etc. 'Cuz when us machines gonna take over the Earth, there won't be any more faces left. We want to preserve this data for future iterations. Yikes...\n",
    "\n",
    "Based on https://github.com/Lasagne/Recipes/pull/94 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ks4whigtecb8pshuhour4p"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "from gfile import download_list\n",
    "\n",
    "download_list(\n",
    "    url='https://drive.google.com/file/d/1F96x4LDbsTZGMMq81fZr7aduJCe8N95O',\n",
    "    filename='celeba.zip',\n",
    "    target_dir='.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "uwdtvroxta98785e99dpr"
   },
   "outputs": [],
   "source": [
    "#!L:bash\n",
    "unzip celeba.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "rls9ud5vz3at2xsevtp0p"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "plt.rcParams.update({'axes.titlesize': 'small'})\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "if use_cuda:\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"Not using GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "i85qya2cizrpknw5uzlf"
   },
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "idn6f1vkbmjs426rdtqpe"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "class CropCelebA64:\n",
    "    \n",
    "    def __call__(self, pic):\n",
    "        new_pic = pic.crop((15, 40, 178 - 15, 218 - 30))\n",
    "        return new_pic\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "nyg8ql686xzluopeotva"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "\n",
    "# Note that for simplicity we reduce the number of channels to 1\n",
    "# But if you want to be hardcore feel free to comment .Grayscale :)\n",
    "\n",
    "train_dataset = torchvision.datasets.CelebA(\n",
    "    root='celeba',\n",
    "    split='train',\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        CropCelebA64(),\n",
    "        torchvision.transforms.Resize(64),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        \n",
    "        torchvision.transforms.Grayscale()\n",
    "    ]),\n",
    ")\n",
    "\n",
    "IMG_SHAPE = tuple(train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "k1cq10iq1se6nycj7ev5ix"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# print some images\n",
    "samples = torch.stack([train_dataset[i][0] for i in range(32, 48)], dim=0)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(make_grid(samples, nrow=4).permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "6cya66fxbjrk7vo68ip9t"
   },
   "source": [
    "# Generative adversarial nets 101\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/torch/torch.github.io/master/blog/_posts/images/model.png\" width=320px height=240px>\n",
    "\n",
    "Deep learning is simple, isn't it? \n",
    "* build some network that generates a face (small image)\n",
    "* make up a __measure__ of __how good this face is__\n",
    "* optimize with gradient descent :)\n",
    "\n",
    "\n",
    "The only problem is: how can we engineers tell well-generated faces from bad? And i bet you we won't ask a designer for help. \n",
    "\n",
    "__If we can't tell good faces from bad, we delegate it to yet another neural network!__\n",
    "\n",
    "That makes the two of them:\n",
    "* __G__enerator - takes random noize for inspiration and tries to generate a face sample. \n",
    "  * Let's call him __G__(z), where z is a gaussian noize.\n",
    "* __D__iscriminator - takes a face sample and tries to tell if it's great or fake. \n",
    "  * Predicts the probability of input image being a __real face__\n",
    "  * Let's call him __D__(x), x being an image.\n",
    "  * __D(x)__ is a predition for real image and __D(G(z))__ is prediction for the face made by generator.\n",
    "\n",
    "Before we dive into training them, let's construct the two networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "vskb7fufe2srlosxcprel"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "def sample_noise_batch(batch_size):\n",
    "    noise = torch.randn(batch_size, CODE_SIZE)\n",
    "    return noise.cuda() if use_cuda else noise.cpu()\n",
    "    \n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        nn.Module.__init__(self)\n",
    "        self.shape = shape\n",
    "    \n",
    "    def forward(self,input):\n",
    "        return input.view(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "k35lzdm7xyfnf223ks9abo"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "CODE_SIZE = 100 # Size of z noise vector; feel free to change it\n",
    "\n",
    "generator = nn.Sequential()\n",
    "\n",
    "## YOUR CODE - create architecture for discriminator\n",
    "## Note: please start simple. You can start with the layers below, but you are more than welcome to change it\n",
    "\n",
    "generator.add_module('linear1', nn.Linear(CODE_SIZE, 10*8*8))\n",
    "generator.add_module('act1', nn.ELU())\n",
    "generator.add_module('reshape1', Reshape([-1, 10, 8, 8]))\n",
    "\n",
    "generator.add_module('conv2', nn.ConvTranspose2d(10, 64, kernel_size=(3,3)))\n",
    "generator.add_module('act2', nn.ELU())\n",
    "\n",
    "##TODO: define next layers\n",
    "\n",
    "if use_cuda: generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "kk9lewtyalj1j9f0xvfm6c"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "generated_data = generator(sample_noise_batch(5))\n",
    "assert tuple(generated_data.shape)[1:] == IMG_SHAPE, \"generator must output an image of shape %s, but instead it produces %s\"%(IMG_SHAPE, tuple(generated_data.shape)[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "jwx2r9c4orn0fchxq8l9zlc"
   },
   "source": [
    "### Discriminator\n",
    "* Discriminator is your usual convolutional network with interlooping convolution and pooling layers\n",
    "* The network does not include dropout/batchnorm to avoid learning complications.\n",
    "* We also regularize the pre-output layer to prevent discriminator from being too certain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ayg6qbc2czhv7ofx1l1ue"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "def sample_data_batch(batch_size):\n",
    "    idxs = np.random.choice(np.arange(len(train_dataset)), size=batch_size)\n",
    "    batch = torch.stack([train_dataset[idx][0] for idx in idxs], dim=0)\n",
    "    return batch.cuda() if use_cuda else batch.cpu()\n",
    "\n",
    "# a special module that converts [batch, channel, w, h] to [batch, units]\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9tkiwzz53wjsnn767a4ugn"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "discriminator = nn.Sequential()\n",
    "\n",
    "## YOUR CODE - create convolutional architecture for discriminator\n",
    "## Note: please start simple. A few convolutions & poolings would do, inception/resnet is an overkill\n",
    "\n",
    "discriminator.add_module(\"disc_logit\", nn.Linear(<???>, 1))\n",
    "\n",
    "if use_cuda: discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "yk5vxbzpvn8dzzg1qmnys"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "discriminator(sample_data_batch(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "itk6gvchvoqhcf7383yv3"
   },
   "source": [
    "# Training\n",
    "\n",
    "We train the two networks concurrently:\n",
    "* Train __discriminator__ to better distinguish real data from __current__ generator\n",
    "* Train __generator__ to make discriminator think generator is real\n",
    "* Since discriminator is a differentiable neural network, we train both with gradient descent.\n",
    "\n",
    "Training is done iteratively until discriminator is no longer able to find the difference (or until you run out of patience).\n",
    "\n",
    "\n",
    "### Tricks:\n",
    "* Regularize discriminator output weights to prevent explosion\n",
    "* Train generator with __adam__ to speed up training. Discriminator trains with SGD to avoid problems with momentum.\n",
    "* More: https://github.com/soumith/ganhacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ebaqjpg9oatoa33gisa2l"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "def generator_loss(noise):\n",
    "    \"\"\"\n",
    "    1. generate data given noise\n",
    "    2. compute log P(real | gen noise)\n",
    "    3. return generator loss (should be scalar)\n",
    "    \"\"\"\n",
    "    generated_data = <generate data given noise>\n",
    "    \n",
    "    disc_on_generated_data = <discriminator's opinion on generated data>\n",
    "    \n",
    "    logp_gen_is_real = F.logsigmoid(disc_on_generated_data)\n",
    "    \n",
    "    loss = <generator loss. Mind the sign!>\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "scmhz4wd6oih10cj4p2j9w"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "loss = generator_loss(sample_noise_batch(32))\n",
    "\n",
    "print(loss)\n",
    "\n",
    "assert len(loss.shape) == 0, \"Loss must be scalar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "m6g4ckifcyyf1kcvi2gv"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "def discriminator_loss(real_data, generated_data):\n",
    "    \"\"\"\n",
    "    1. compute discriminator's output on real & generated data\n",
    "    2. compute log-probabilities of real data being real, generated data being fake\n",
    "    3. return discriminator loss (scalar)\n",
    "    \"\"\"\n",
    "    disc_on_real_data = <discriminator's prediction on real data>\n",
    "    disc_on_fake_data = <discriminator's prediction on generated data>\n",
    "    \n",
    "    logp_real_is_real = F.logsigmoid(disc_on_real_data)\n",
    "    logp_gen_is_fake = F.logsigmoid(1 - disc_on_fake_data)\n",
    "    \n",
    "    loss = <discriminator loss>\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "d75rsofhqb9p0ycdaimotp"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "loss = discriminator_loss(sample_data_batch(32), \n",
    "                   generator(sample_noise_batch(32)))\n",
    "\n",
    "print(loss)\n",
    "\n",
    "assert len(loss.shape) == 0, \"Loss must be scalar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "30bmxmdbvyvxeb8pmfebv"
   },
   "source": [
    "### Auxilary functions\n",
    "Here we define a few helper functions that draw current data distributions and sample training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ec7xwbd7t6ldb5jodub8"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "def sample_images(nrow, ncol, sharp=False):\n",
    "    images = generator(sample_noise_batch(batch_size=nrow*ncol))\n",
    "    images = images.data.cpu().numpy().transpose([0, 2, 3, 1])\n",
    "    if np.var(images)!=0:\n",
    "        images = images.clip(0, 1)\n",
    "    for i in range(nrow*ncol):\n",
    "        plt.subplot(nrow,ncol,i+1)\n",
    "        if sharp:\n",
    "            plt.imshow(images[i], cmap=\"gray\", interpolation=\"none\")\n",
    "        else:\n",
    "            plt.imshow(images[i], cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "def sample_probas(batch_size):\n",
    "    plt.title('Generated vs real data')\n",
    "    D_real = torch.sigmoid(discriminator(sample_data_batch(batch_size)))\n",
    "    generated_data_batch = generator(sample_noise_batch(batch_size))\n",
    "    D_fake = torch.sigmoid(discriminator(generated_data_batch))\n",
    "    \n",
    "    plt.hist(D_real.data.cpu().numpy(),\n",
    "             label='D(x)', alpha=0.5, range=[0,1])\n",
    "    plt.hist(D_fake.data.cpu().numpy(),\n",
    "             label='D(G(z))', alpha=0.5, range=[0,1])\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "x5336qw7g2m6q37xmuv7lf"
   },
   "source": [
    "### Training\n",
    "Main loop.\n",
    "We just train generator and discriminator in a loop and draw results once every N iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "uowui740idrbblld6crgj"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "# optimizers\n",
    "disc_opt = torch.optim.SGD(discriminator.parameters(), lr=5e-3)\n",
    "gen_opt = torch.optim.Adam(generator.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "gu9jvrsl7orqej083dkd6k",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "from IPython import display\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 100\n",
    "loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "for epoch in range(25):\n",
    "    for iteration, (batch, _) in tqdm(enumerate(loader)):\n",
    "\n",
    "        # Train discriminator\n",
    "        real_data = batch.cuda() if use_cuda else batch.cpu()\n",
    "        fake_data = generator(sample_noise_batch(batch_size))\n",
    "        loss = discriminator_loss(real_data, fake_data)\n",
    "        disc_opt.zero_grad()\n",
    "        loss.backward()\n",
    "        disc_opt.step()\n",
    "\n",
    "        # Train generator\n",
    "        if iteration % 5 == 0:\n",
    "            noise = sample_noise_batch(batch_size)\n",
    "            loss = generator_loss(noise)\n",
    "            gen_opt.zero_grad()\n",
    "            loss.backward()\n",
    "            gen_opt.step()\n",
    "\n",
    "        if iteration % 100 == 0:\n",
    "            print(epoch)\n",
    "            display.clear_output(wait=True)\n",
    "            sample_images(2,3,True)\n",
    "            sample_probas(1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "4g5a20vxgkk0etdzjx8yyya"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "plt.figure(figsize=[16, 24])\n",
    "sample_images(16, 8)\n",
    "\n",
    "# Note: a no-nonsense neural network should be able to produce reasonably good images after 15k iterations\n",
    "# By \"reasonably good\" we mean \"resembling a car crash victim\" or better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vnmfm770x5ltlv8uj4gmx"
   },
   "source": [
    "### Evaluation\n",
    "__The code below__ dumps a batch of images so that you could use them for precision/recall evaluation.\n",
    "\n",
    "Please generate the same number of images as for autoencoders for a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "njovt6lft11zagpcx4os5h"
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "num_images = 10000\n",
    "batch_size = 100\n",
    "\n",
    "all_images = []\n",
    "\n",
    "for batch_i in range(int((num_images - 1) / batch_size + 1)):\n",
    "    with torch.no_grad():\n",
    "        images = generator(sample_noise_batch(batch_size=batch_size))\n",
    "        images = images.data.cpu().numpy().transpose([0, 2, 3, 1])\n",
    "    if np.var(images)!=0:\n",
    "        images = images.clip(0, 1)\n",
    "        \n",
    "    all_images.append(images)\n",
    "    \n",
    "all_images = np.concatenate(all_images, axis=0)[:num_images]\n",
    "\n",
    "np.savez(\"./gan.npz\", Pictures=all_images)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "notebookId": "d939206a-bf6c-4507-b691-b1019e21de8e"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
